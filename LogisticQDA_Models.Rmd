---
title: "Logistic_QDA"
author: "David Chen"
date: "5/2/2020"
output: html_document
---


# Note: This is a huge work in process. Currently we are just trying basic ideas. 


## Work I still need to get done:

1. Including interactions
2. Best subset selection




---




Here we will implement the Logistic Regression / QDA Model

First import all the necessary data and packages

```{r warning = F, message = F}
# Clean up R environment
rm(list = ls())

# Load in packages
library(tidyverse) # Data wrangling, ggplot, etc.
library(knitr)     # This is to make pretty tables (see kable() )
library(MASS)      # For QDA function 


# Read in training and testing data
model_test <- 
  readRDS("./Data/model_test.RDS") 
model_train <- 
  readRDS("./Data/model_train.RDS")

# Global options
set.seed(14)
theme_set(theme_bw()) # Set a better ggplot theme
options(digits=3)     # Set digits to 3 to avoid too many values
```


# Seasonal Only
```{r}
seasonal_train <- 
  model_train %>%
  select(-h1n1_vaccine, -respondent_id)

seasonal_test <-
  model_test %>%
  select(-h1n1_vaccine, -respondent_id)
```


# Initial testing

```{r echo = F}
# Fit logistic reg on full data
Full_glm <- 
  glm(seasonal_vaccine~., data = seasonal_train, family = binomial)
summary(Full_glm)
```


## Full model - LR - Training error rates

```{r echo = F}
# Get the number of rows
n_train <- nrow(seasonal_train)

# Store the predictions on the existing data
glm.probs <- predict(Full_glm, type = 'response')

# Determine predictions
glm.pred <- rep(0, n_train)
glm.pred[glm.probs > .5] <- 1

# Generate confusion matrix
table(glm.pred, seasonal_train$seasonal_vaccine)
```

Training error rate of 78.2%, compared to naive 52.2%. Not too bad!

```{r}
# Proportion of correct responses
mean(glm.pred == seasonal_train$seasonal_vaccine)

# Proportion correct if you just no each time - 52%
mean(0 == seasonal_train$seasonal_vaccine)

```

## Full model - LR -  testing error rates


```{r echo = F}
# Get the number of rows
n_test <- nrow(seasonal_test)

# Store the predictions on the existing data
glm.probs <- predict(Full_glm, newdata = seasonal_test,type = 'response')

# Determine predictions
glm.pred <- rep(0, n_test)
glm.pred[glm.probs > .5] <- 1

# Generate confusion matrix
table(glm.pred, seasonal_test$seasonal_vaccine)
```


Applied to the testing set, the testing error rate only dips slightly to 77.9%. The naive model would have done 52.2%. 
```{r}
# Proportion of correct responses
mean(glm.pred == seasonal_test$seasonal_vaccine)

# Proportion correct if you just no each time - 52%
mean(0 == seasonal_test$seasonal_vaccine)
```



############################

# Trying out stepwise selection

```{r}
# Both directions
step_glm <- step(Full_glm, trace = FALSE)
summary(step_glm)
```

```{r echo = F}
# Store the predictions on the existing data
step_probs <- predict(step_glm, type = 'response')

# Determine predictions
step_pred <- rep(0, n_train)
step_pred[step_probs > .5] <- 1

# Generate confusion matrix
table(step_probs, seasonal_train$seasonal_vaccine)
```

Training error rate increases by 0.1%... it seems like our basic stepwise selection won't be as effective.

```{r}
# Proportion of correct responses
mean(step_pred == seasonal_train$seasonal_vaccine)
```





###########################################################################


# QDA

## Fitting QDA with all variables
```{r echo = F}
# Fit the QDA
qda.fit <- qda(seasonal_vaccine~., data = seasonal_train)
qda.pred <- predict(qda.fit, seasonal_train)
qda.class <- qda.pred$class

# Confusion Matrix
table(qda.class, seasonal_train$seasonal_vaccine)
```

```{r}
mean(qda.class == seasonal_train$seasonal_vaccine)
```

Applying to testing set
```{r echo = F}
# Fit the QDA
qda_test_pred <- predict(qda.fit, seasonal_test)
qda_test_class <- qda_test_pred$class

# Confusion Matrix
table(qda_test_class, seasonal_test$seasonal_vaccine)
```

```{r}
mean(qda_test_class == seasonal_test$seasonal_vaccine)
```
















